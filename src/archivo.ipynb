{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKzE3UlOKBm2"
      },
      "source": [
        "### Assigment: Logistic Regression and Multiclass Extensions\n",
        "\n",
        "A) Binary Logistic Regression from Scratch\n",
        "\n",
        "1. Dataset Use the Heart Disease dataset from the UCI repository. Originally, the Y variable is an integer with varying values. Recode it to be either 0 (when the original value is 0) or 1 (otherwise).\n",
        "\n",
        "    - Task: predict whether a patient has heart disease.\n",
        "    - Standardize numeric features, one-hot encode categorical ones.\n",
        "    - Split into 70% train / 30% test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "un5fUpKTKYLN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Logistic Regression — From Scratch: Part A, B (OvA), C (Softmax)\n",
        "# ============================================================\n",
        "\n",
        "!pip -q install ucimlrepo\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "np.random.seed(42)\n",
        "RANDOM_STATE = 42\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Lvk7x18MK8sD"
      },
      "outputs": [],
      "source": [
        "heart_disease = fetch_ucirepo(id = 45)\n",
        "X = heart_disease.data.features # features\n",
        "Y = heart_disease.data.targets # heart disease diagnosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "fuzwe5E3K8yD",
        "outputId": "1938b9f7-a426-4a65-bb30-c8fecc100e73"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>role</th>\n",
              "      <th>type</th>\n",
              "      <th>demographic</th>\n",
              "      <th>description</th>\n",
              "      <th>units</th>\n",
              "      <th>missing_values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>age</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>Age</td>\n",
              "      <td>None</td>\n",
              "      <td>years</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sex</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Categorical</td>\n",
              "      <td>Sex</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cp</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Categorical</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>trestbps</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>resting blood pressure (on admission to the ho...</td>\n",
              "      <td>mm Hg</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>chol</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>serum cholestoral</td>\n",
              "      <td>mg/dl</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>fbs</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Categorical</td>\n",
              "      <td>None</td>\n",
              "      <td>fasting blood sugar &gt; 120 mg/dl</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>restecg</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Categorical</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>thalach</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>maximum heart rate achieved</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>exang</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Categorical</td>\n",
              "      <td>None</td>\n",
              "      <td>exercise induced angina</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>oldpeak</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>ST depression induced by exercise relative to ...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>slope</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Categorical</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ca</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>number of major vessels (0-3) colored by flour...</td>\n",
              "      <td>None</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>thal</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Categorical</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>num</td>\n",
              "      <td>Target</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>diagnosis of heart disease</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        name     role         type demographic  \\\n",
              "0        age  Feature      Integer         Age   \n",
              "1        sex  Feature  Categorical         Sex   \n",
              "2         cp  Feature  Categorical        None   \n",
              "3   trestbps  Feature      Integer        None   \n",
              "4       chol  Feature      Integer        None   \n",
              "5        fbs  Feature  Categorical        None   \n",
              "6    restecg  Feature  Categorical        None   \n",
              "7    thalach  Feature      Integer        None   \n",
              "8      exang  Feature  Categorical        None   \n",
              "9    oldpeak  Feature      Integer        None   \n",
              "10     slope  Feature  Categorical        None   \n",
              "11        ca  Feature      Integer        None   \n",
              "12      thal  Feature  Categorical        None   \n",
              "13       num   Target      Integer        None   \n",
              "\n",
              "                                          description  units missing_values  \n",
              "0                                                None  years             no  \n",
              "1                                                None   None             no  \n",
              "2                                                None   None             no  \n",
              "3   resting blood pressure (on admission to the ho...  mm Hg             no  \n",
              "4                                   serum cholestoral  mg/dl             no  \n",
              "5                     fasting blood sugar > 120 mg/dl   None             no  \n",
              "6                                                None   None             no  \n",
              "7                         maximum heart rate achieved   None             no  \n",
              "8                             exercise induced angina   None             no  \n",
              "9   ST depression induced by exercise relative to ...   None             no  \n",
              "10                                               None   None             no  \n",
              "11  number of major vessels (0-3) colored by flour...   None            yes  \n",
              "12                                               None   None            yes  \n",
              "13                         diagnosis of heart disease   None             no  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "heart_disease.variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRRUBau9LhgS",
        "outputId": "43023722-3c14-43d9-d2c0-cd1418c973a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Porcentaje de valores faltantes por variable:\n",
            "        name  missing_count  missing_%\n",
            "0         ca              4       1.32\n",
            "1       thal              2       0.66\n",
            "2         cp              0       0.00\n",
            "3        sex              0       0.00\n",
            "4        age              0       0.00\n",
            "5       chol              0       0.00\n",
            "6   trestbps              0       0.00\n",
            "7        fbs              0       0.00\n",
            "8    restecg              0       0.00\n",
            "9      exang              0       0.00\n",
            "10   thalach              0       0.00\n",
            "11     slope              0       0.00\n",
            "12   oldpeak              0       0.00\n"
          ]
        }
      ],
      "source": [
        "# Calcular número y porcentaje de valores faltantes\n",
        "missing_summary = pd.DataFrame({\n",
        "    'name': X.columns,\n",
        "    'missing_count': X.isnull().sum(),\n",
        "    'missing_%': (X.isnull().mean() * 100).round(2)\n",
        "})\n",
        "# Ordenar de mayor a menor porcentaje de faltantes\n",
        "missing_summary = missing_summary.sort_values(by='missing_%', ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Mostrar resultado\n",
        "print(\"Porcentaje de valores faltantes por variable:\")\n",
        "print(missing_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cURNq99gLx48"
      },
      "outputs": [],
      "source": [
        "#Reemplazando missing values con la mediana\n",
        "X = X.fillna(X.median())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "Ueiupow7L1nt",
        "outputId": "21b6ef70-86c3-4936-9b7c-9af8e92209ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "age         0\n",
              "sex         0\n",
              "cp          0\n",
              "trestbps    0\n",
              "chol        0\n",
              "fbs         0\n",
              "restecg     0\n",
              "thalach     0\n",
              "exang       0\n",
              "oldpeak     0\n",
              "slope       0\n",
              "ca          0\n",
              "thal        0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "MGbhtaj9L4Mq",
        "outputId": "4a7e05ef-d3cb-42e2-a51e-89c46275b8f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "num    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "W91xeAJbL7uG",
        "outputId": "998d1429-b05b-4dce-ad67-20dadf9c3b18"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num\n",
              "0    0\n",
              "1    2\n",
              "2    1\n",
              "3    0\n",
              "4    0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UTf1St6ZMD1w"
      },
      "outputs": [],
      "source": [
        "#Recoding de Y a 1 si es mayor a 0\n",
        "Y = pd.DataFrame(np.where(Y > 0, 1, 0), columns=Y.columns)\n",
        "#Aplanando Y (303,1) -> (303,)\n",
        "Y = Y.values.ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2_1jYyyMFy6",
        "outputId": "0869a41f-3b4d-4a7a-cf79-66bbfa6527f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(303,)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9huTyVqMHiN",
        "outputId": "8e539f2e-7a51-4d44-f5ee-9355a3ba3ef1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN1hlCsEM0JC",
        "outputId": "0a0ce2c6-9cec-4144-b84c-e2543893f2cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    0.0\n",
            "1    3.0\n",
            "2    2.0\n",
            "3    0.0\n",
            "4    0.0\n",
            "Name: ca, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Ver primeras filas de la variable\n",
        "print(X['ca'].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "awCFMQs4NLEW"
      },
      "outputs": [],
      "source": [
        "#Se realiza la categorizacion One- Hoy enconde porque no se cosnidera un orden entre las variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "d9GrH0QxNWEq"
      },
      "outputs": [],
      "source": [
        "#One hot encode ->\n",
        "X_oneHot = pd.get_dummies(X, columns=[\"sex\",\"cp\",\"fbs\",\"restecg\",\"exang\",\"slope\",\"ca\",\"thal\"])\n",
        "# Intercepto y convirtiendo todo a float\n",
        "X_oneHot[\"Intercepto\"]=1\n",
        "X_oneHot = X_oneHot.astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "zK9h4mU1NcBz",
        "outputId": "f968e17b-9a2d-4767-f5de-587e360bcc22"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>thalach</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>sex_0</th>\n",
              "      <th>sex_1</th>\n",
              "      <th>cp_1</th>\n",
              "      <th>cp_2</th>\n",
              "      <th>cp_3</th>\n",
              "      <th>...</th>\n",
              "      <th>slope_2</th>\n",
              "      <th>slope_3</th>\n",
              "      <th>ca_0.0</th>\n",
              "      <th>ca_1.0</th>\n",
              "      <th>ca_2.0</th>\n",
              "      <th>ca_3.0</th>\n",
              "      <th>thal_3.0</th>\n",
              "      <th>thal_6.0</th>\n",
              "      <th>thal_7.0</th>\n",
              "      <th>Intercepto</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>233.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>286.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>67.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>45.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>264.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>68.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>57.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>57.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>236.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>38.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>303 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age  trestbps   chol  thalach  oldpeak  sex_0  sex_1  cp_1  cp_2  cp_3  \\\n",
              "0    63.0     145.0  233.0    150.0      2.3    0.0    1.0   1.0   0.0   0.0   \n",
              "1    67.0     160.0  286.0    108.0      1.5    0.0    1.0   0.0   0.0   0.0   \n",
              "2    67.0     120.0  229.0    129.0      2.6    0.0    1.0   0.0   0.0   0.0   \n",
              "3    37.0     130.0  250.0    187.0      3.5    0.0    1.0   0.0   0.0   1.0   \n",
              "4    41.0     130.0  204.0    172.0      1.4    1.0    0.0   0.0   1.0   0.0   \n",
              "..    ...       ...    ...      ...      ...    ...    ...   ...   ...   ...   \n",
              "298  45.0     110.0  264.0    132.0      1.2    0.0    1.0   1.0   0.0   0.0   \n",
              "299  68.0     144.0  193.0    141.0      3.4    0.0    1.0   0.0   0.0   0.0   \n",
              "300  57.0     130.0  131.0    115.0      1.2    0.0    1.0   0.0   0.0   0.0   \n",
              "301  57.0     130.0  236.0    174.0      0.0    1.0    0.0   0.0   1.0   0.0   \n",
              "302  38.0     138.0  175.0    173.0      0.0    0.0    1.0   0.0   0.0   1.0   \n",
              "\n",
              "     ...  slope_2  slope_3  ca_0.0  ca_1.0  ca_2.0  ca_3.0  thal_3.0  \\\n",
              "0    ...      0.0      1.0     1.0     0.0     0.0     0.0       0.0   \n",
              "1    ...      1.0      0.0     0.0     0.0     0.0     1.0       1.0   \n",
              "2    ...      1.0      0.0     0.0     0.0     1.0     0.0       0.0   \n",
              "3    ...      0.0      1.0     1.0     0.0     0.0     0.0       1.0   \n",
              "4    ...      0.0      0.0     1.0     0.0     0.0     0.0       1.0   \n",
              "..   ...      ...      ...     ...     ...     ...     ...       ...   \n",
              "298  ...      1.0      0.0     1.0     0.0     0.0     0.0       0.0   \n",
              "299  ...      1.0      0.0     0.0     0.0     1.0     0.0       0.0   \n",
              "300  ...      1.0      0.0     0.0     1.0     0.0     0.0       0.0   \n",
              "301  ...      1.0      0.0     0.0     1.0     0.0     0.0       1.0   \n",
              "302  ...      0.0      0.0     1.0     0.0     0.0     0.0       1.0   \n",
              "\n",
              "     thal_6.0  thal_7.0  Intercepto  \n",
              "0         1.0       0.0         1.0  \n",
              "1         0.0       0.0         1.0  \n",
              "2         0.0       1.0         1.0  \n",
              "3         0.0       0.0         1.0  \n",
              "4         0.0       0.0         1.0  \n",
              "..        ...       ...         ...  \n",
              "298       0.0       1.0         1.0  \n",
              "299       0.0       1.0         1.0  \n",
              "300       0.0       1.0         1.0  \n",
              "301       0.0       0.0         1.0  \n",
              "302       0.0       0.0         1.0  \n",
              "\n",
              "[303 rows x 29 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_oneHot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BbsGsF0gNqBY"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_oneHot, Y, train_size = .7, shuffle = True, random_state=5102025)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FSGwpbMNr1z",
        "outputId": "6ab58568-00f6-48b4-8637-d12572ad404a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(212, 29)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxAwCTx0NtW-",
        "outputId": "ca9e45e9-0259-4ae5-87e0-f38dda127a05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(212,)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PLlTnhqCNwOg"
      },
      "outputs": [],
      "source": [
        "#Estandarizando columnas numericas\n",
        "num_cols = [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\"]\n",
        "\n",
        "X_train_mean = X_train[num_cols].mean()\n",
        "X_train_std = X_train[num_cols].std()\n",
        "\n",
        "X_train[num_cols] = (X_train[num_cols] - X_train_mean) / X_train_std\n",
        "X_test[num_cols] = (X_test[num_cols] - X_train_mean) / X_train_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-NEWRRvNx9s",
        "outputId": "237f42ff-ffb5-44d5-e52e-045a657d58f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 212 entries, 139 to 50\n",
            "Data columns (total 29 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   age         212 non-null    float64\n",
            " 1   trestbps    212 non-null    float64\n",
            " 2   chol        212 non-null    float64\n",
            " 3   thalach     212 non-null    float64\n",
            " 4   oldpeak     212 non-null    float64\n",
            " 5   sex_0       212 non-null    float64\n",
            " 6   sex_1       212 non-null    float64\n",
            " 7   cp_1        212 non-null    float64\n",
            " 8   cp_2        212 non-null    float64\n",
            " 9   cp_3        212 non-null    float64\n",
            " 10  cp_4        212 non-null    float64\n",
            " 11  fbs_0       212 non-null    float64\n",
            " 12  fbs_1       212 non-null    float64\n",
            " 13  restecg_0   212 non-null    float64\n",
            " 14  restecg_1   212 non-null    float64\n",
            " 15  restecg_2   212 non-null    float64\n",
            " 16  exang_0     212 non-null    float64\n",
            " 17  exang_1     212 non-null    float64\n",
            " 18  slope_1     212 non-null    float64\n",
            " 19  slope_2     212 non-null    float64\n",
            " 20  slope_3     212 non-null    float64\n",
            " 21  ca_0.0      212 non-null    float64\n",
            " 22  ca_1.0      212 non-null    float64\n",
            " 23  ca_2.0      212 non-null    float64\n",
            " 24  ca_3.0      212 non-null    float64\n",
            " 25  thal_3.0    212 non-null    float64\n",
            " 26  thal_6.0    212 non-null    float64\n",
            " 27  thal_7.0    212 non-null    float64\n",
            " 28  Intercepto  212 non-null    float64\n",
            "dtypes: float64(29)\n",
            "memory usage: 49.7 KB\n"
          ]
        }
      ],
      "source": [
        "X_train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dLfqu5QN1c0"
      },
      "source": [
        "2. Model Derivation and Implementation\n",
        "    \n",
        "    - Implement gradient descent to maximize the log-likelihood (or equivalently, minimize the negative log-likelihood).\n",
        "    - Show convergence plots for at least two learning rates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7qLz408dUSRF"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "\n",
        "def f(X, theta):\n",
        "    \"\"\"The sigmoid model we are trying to fit.\n",
        "\n",
        "    Parameters:\n",
        "    theta (np.array): d-dimensional vector of parameters\n",
        "    X (np.array): (n,d)-dimensional data matrix\n",
        "\n",
        "    Returns:\n",
        "    y_pred (np.array): n-dimensional vector of predicted targets\n",
        "    \"\"\"\n",
        "    return sigmoid(X.dot(theta))\n",
        "\n",
        "def log_likelihood(theta, X, y):\n",
        "    \"\"\"The cost function, J(theta0, theta1) describing the goodness of fit.\n",
        "\n",
        "    We added the 1e-6 term in order to avoid overflow (inf and -inf).\n",
        "\n",
        "    Parameters:\n",
        "    theta (np.array): d-dimensional vector of parameters\n",
        "    X (np.array): (n,d)-dimensional design matrix\n",
        "    y (np.array): n-dimensional vector of targets\n",
        "    \"\"\"\n",
        "    return (y*np.log(f(X, theta) + 1e-6) + (1-y)*np.log(1-f(X, theta) + 1e-6)).mean()\n",
        "\n",
        "def loglik_gradient(theta, X, y):\n",
        "    \"\"\"The cost function, J(theta0, theta1) describing the goodness of fit.\n",
        "\n",
        "    Parameters:\n",
        "    theta (np.array): d-dimensional vector of parameters\n",
        "    X (np.array): (n,d)-dimensional design matrix\n",
        "    y (np.array): n-dimensional vector of targets\n",
        "\n",
        "    Returns:\n",
        "    grad (np.array): d-dimensional gradient of the MSE\n",
        "    \"\"\"\n",
        "    return np.mean((f(X, theta)-y) * X.T, axis=1)\n",
        "\n",
        "class gradient_descent():\n",
        "    def __init__(self ,step_size, X_train, y_train ,threshold = 5e-5):\n",
        "\n",
        "        self.step_size = step_size\n",
        "        self.X_train = np.array(X_train) # DataFrame a np.array\n",
        "        self.y_train = np.array(y_train)\n",
        "        self.threshold = threshold\n",
        "        self.theta = np.zeros(X_train.shape[1])\n",
        "        self.theta_prev = np.ones(X_train.shape[1])\n",
        "        self.iter = 0\n",
        "        self.costo = []\n",
        "        self.coeficientes = None\n",
        "\n",
        "    def fit(self):\n",
        "        print(\"===================\")\n",
        "        print(\"TASA DE APRENDIZAJE: %.4f\" %(self.step_size))\n",
        "        print(\"===================\")\n",
        "\n",
        "        while np.linalg.norm(self.theta - self.theta_prev) > self.threshold:\n",
        "            log_lik = log_likelihood(self.theta, self.X_train, self.y_train)\n",
        "            self.costo.append(log_lik)\n",
        "\n",
        "            if self.iter % 500 == 0:\n",
        "                print('Iteracion %d. Log-likelihood: %.6f' % (self.iter, log_lik))\n",
        "            self.theta_prev = self.theta.copy()\n",
        "            gradient = loglik_gradient(self.theta, self.X_train, self.y_train)\n",
        "            self.theta = self.theta_prev - self.step_size * gradient\n",
        "            self.iter += 1\n",
        "        self.coeficientes = self.theta.copy()\n",
        "\n",
        "        print(\"\\nCoeficientes:\")\n",
        "        print(self.coeficientes)\n",
        "        print(\"\\nNro. Iteraciones: %d\" % (self.iter))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tY8o_i9MUVj9",
        "outputId": "409a2657-0460-4a8d-e059-52024d890385"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===================\n",
            "TASA DE APRENDIZAJE: 0.1000\n",
            "===================\n",
            "Iteracion 0. Log-likelihood: -0.693145\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteracion 500. Log-likelihood: -0.321572\n",
            "Iteracion 1000. Log-likelihood: -0.313214\n",
            "Iteracion 1500. Log-likelihood: -0.310562\n",
            "Iteracion 2000. Log-likelihood: -0.309420\n",
            "Iteracion 2500. Log-likelihood: -0.308847\n",
            "Iteracion 3000. Log-likelihood: -0.308528\n",
            "Iteracion 3500. Log-likelihood: -0.308334\n",
            "Iteracion 4000. Log-likelihood: -0.308208\n",
            "Iteracion 4500. Log-likelihood: -0.308120\n",
            "Iteracion 5000. Log-likelihood: -0.308056\n",
            "Iteracion 5500. Log-likelihood: -0.308005\n",
            "Iteracion 6000. Log-likelihood: -0.307965\n",
            "Iteracion 6500. Log-likelihood: -0.307931\n",
            "Iteracion 7000. Log-likelihood: -0.307902\n",
            "Iteracion 7500. Log-likelihood: -0.307876\n",
            "Iteracion 8000. Log-likelihood: -0.307854\n",
            "Iteracion 8500. Log-likelihood: -0.307833\n",
            "Iteracion 9000. Log-likelihood: -0.307814\n",
            "Iteracion 9500. Log-likelihood: -0.307796\n",
            "Iteracion 10000. Log-likelihood: -0.307780\n",
            "Iteracion 10500. Log-likelihood: -0.307764\n",
            "Iteracion 11000. Log-likelihood: -0.307750\n",
            "Iteracion 11500. Log-likelihood: -0.307736\n",
            "\n",
            "Coeficientes:\n",
            "[-3.93806393e-01  7.20271975e-01  2.09014706e-01 -9.12482669e-01\n",
            "  2.21982894e-01 -8.14667744e-01  8.19432708e-01 -1.13237534e+00\n",
            " -6.47357813e-01  1.09566023e-01  1.67493209e+00  4.91789806e-03\n",
            " -1.52934446e-04 -6.21400029e-01  7.61893834e-01 -1.35728841e-01\n",
            " -3.57819593e-01  3.62584557e-01 -8.99806199e-02  4.59424435e-01\n",
            " -3.64678852e-01 -1.76245380e+00 -2.44192384e-01  1.65280347e+00\n",
            "  3.58607677e-01 -5.36173353e-01 -3.35391999e-01  8.76330315e-01\n",
            "  4.76496361e-03]\n",
            "\n",
            "Nro. Iteraciones: 11950\n",
            "===================\n",
            "TASA DE APRENDIZAJE: 0.0100\n",
            "===================\n",
            "Iteracion 0. Log-likelihood: -0.693145\n",
            "Iteracion 500. Log-likelihood: -0.404042\n",
            "Iteracion 1000. Log-likelihood: -0.367754\n",
            "Iteracion 1500. Log-likelihood: -0.351774\n",
            "Iteracion 2000. Log-likelihood: -0.342414\n",
            "Iteracion 2500. Log-likelihood: -0.336162\n",
            "Iteracion 3000. Log-likelihood: -0.331652\n",
            "Iteracion 3500. Log-likelihood: -0.328230\n",
            "Iteracion 4000. Log-likelihood: -0.325542\n",
            "Iteracion 4500. Log-likelihood: -0.323375\n",
            "Iteracion 5000. Log-likelihood: -0.321594\n",
            "Iteracion 5500. Log-likelihood: -0.320106\n",
            "Iteracion 6000. Log-likelihood: -0.318848\n",
            "Iteracion 6500. Log-likelihood: -0.317772\n",
            "Iteracion 7000. Log-likelihood: -0.316844\n",
            "Iteracion 7500. Log-likelihood: -0.316037\n",
            "Iteracion 8000. Log-likelihood: -0.315329\n",
            "Iteracion 8500. Log-likelihood: -0.314706\n",
            "Iteracion 9000. Log-likelihood: -0.314153\n",
            "Iteracion 9500. Log-likelihood: -0.313661\n",
            "Iteracion 10000. Log-likelihood: -0.313221\n",
            "Iteracion 10500. Log-likelihood: -0.312826\n",
            "Iteracion 11000. Log-likelihood: -0.312469\n",
            "Iteracion 11500. Log-likelihood: -0.312147\n",
            "Iteracion 12000. Log-likelihood: -0.311855\n",
            "Iteracion 12500. Log-likelihood: -0.311589\n",
            "Iteracion 13000. Log-likelihood: -0.311347\n",
            "Iteracion 13500. Log-likelihood: -0.311126\n",
            "Iteracion 14000. Log-likelihood: -0.310923\n",
            "Iteracion 14500. Log-likelihood: -0.310737\n",
            "Iteracion 15000. Log-likelihood: -0.310565\n",
            "Iteracion 15500. Log-likelihood: -0.310408\n",
            "Iteracion 16000. Log-likelihood: -0.310262\n",
            "Iteracion 16500. Log-likelihood: -0.310128\n",
            "\n",
            "Coeficientes:\n",
            "[-0.33124782  0.63807472  0.17707657 -0.80165099  0.28946067 -0.69382517\n",
            "  0.65216395 -0.86743951 -0.61400091 -0.09632947  1.53610868 -0.04388768\n",
            "  0.00222647 -0.34119774  0.18390502  0.11563151 -0.34506652  0.30340531\n",
            " -0.07439394  0.3999208  -0.36718808 -1.58527938 -0.03811545  1.07108471\n",
            "  0.5106489  -0.63952099 -0.18392327  0.78178305 -0.04166121]\n",
            "\n",
            "Nro. Iteraciones: 16723\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "### StepSize 0.1\n",
        "step_size_1 = 1e-1\n",
        "gd_1=gradient_descent(step_size_1,X_train,y_train)\n",
        "gd_1.fit()\n",
        "\n",
        "### StepSize 0.01\n",
        "step_size_2 = 1e-2\n",
        "gd_2=gradient_descent(step_size_2,X_train,y_train)\n",
        "gd_2.fit()\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.plot(range(len(gd_1.costo)), gd_1.costo, 'b-', label=f'Step size = {gd_1.step_size}', linewidth=2)\n",
        "plt.plot(range(len(gd_2.costo)), gd_2.costo, 'r-', label=f'Step size = {gd_2.step_size}', linewidth=2)\n",
        "\n",
        "plt.xlabel('Iteraciones')\n",
        "plt.ylabel('Log_Like')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 958
        },
        "id": "kJsGpV5uU0tk",
        "outputId": "db56e8c0-f3bd-4764-d504-20b3418db16f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>-0.393806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>trestbps</th>\n",
              "      <td>0.720272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chol</th>\n",
              "      <td>0.209015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>thalach</th>\n",
              "      <td>-0.912483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>oldpeak</th>\n",
              "      <td>0.221983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex_0</th>\n",
              "      <td>-0.814668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex_1</th>\n",
              "      <td>0.819433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cp_1</th>\n",
              "      <td>-1.132375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cp_2</th>\n",
              "      <td>-0.647358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cp_3</th>\n",
              "      <td>0.109566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cp_4</th>\n",
              "      <td>1.674932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fbs_0</th>\n",
              "      <td>0.004918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fbs_1</th>\n",
              "      <td>-0.000153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>restecg_0</th>\n",
              "      <td>-0.621400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>restecg_1</th>\n",
              "      <td>0.761894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>restecg_2</th>\n",
              "      <td>-0.135729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>exang_0</th>\n",
              "      <td>-0.357820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>exang_1</th>\n",
              "      <td>0.362585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>slope_1</th>\n",
              "      <td>-0.089981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>slope_2</th>\n",
              "      <td>0.459424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>slope_3</th>\n",
              "      <td>-0.364679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ca_0.0</th>\n",
              "      <td>-1.762454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ca_1.0</th>\n",
              "      <td>-0.244192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ca_2.0</th>\n",
              "      <td>1.652803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ca_3.0</th>\n",
              "      <td>0.358608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>thal_3.0</th>\n",
              "      <td>-0.536173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>thal_6.0</th>\n",
              "      <td>-0.335392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>thal_7.0</th>\n",
              "      <td>0.876330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Intercepto</th>\n",
              "      <td>0.004765</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   0\n",
              "age        -0.393806\n",
              "trestbps    0.720272\n",
              "chol        0.209015\n",
              "thalach    -0.912483\n",
              "oldpeak     0.221983\n",
              "sex_0      -0.814668\n",
              "sex_1       0.819433\n",
              "cp_1       -1.132375\n",
              "cp_2       -0.647358\n",
              "cp_3        0.109566\n",
              "cp_4        1.674932\n",
              "fbs_0       0.004918\n",
              "fbs_1      -0.000153\n",
              "restecg_0  -0.621400\n",
              "restecg_1   0.761894\n",
              "restecg_2  -0.135729\n",
              "exang_0    -0.357820\n",
              "exang_1     0.362585\n",
              "slope_1    -0.089981\n",
              "slope_2     0.459424\n",
              "slope_3    -0.364679\n",
              "ca_0.0     -1.762454\n",
              "ca_1.0     -0.244192\n",
              "ca_2.0      1.652803\n",
              "ca_3.0      0.358608\n",
              "thal_3.0   -0.536173\n",
              "thal_6.0   -0.335392\n",
              "thal_7.0    0.876330\n",
              "Intercepto  0.004765"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Parámetros GD para step size = 0.1\n",
        "param_GD = pd.DataFrame(data=[gd_1.coeficientes], columns=X_train.columns)\n",
        "param_GD.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlWhxwYaU4NM"
      },
      "source": [
        "3. Evaluation\n",
        "\n",
        "    - Compute accuracy, precision, recall, F1 score in the test set.\n",
        "    - Compare with sklearn.linear_model.LogisticRegression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "BX6WUzNAU9jt"
      },
      "outputs": [],
      "source": [
        "def show_metric(my_metric):\n",
        "  return \"{:.2f}%\".format(my_metric * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqnRhzNxU_-h",
        "outputId": "454034e1-2a68-45d3-c56e-e03fc1e281e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: 84.62%\n",
            "precision: 92.31%\n",
            "recall: 76.60%\n",
            "F1 score: 83.72%\n",
            "matriz de confusion:  [[41  3]\n",
            " [11 36]]\n"
          ]
        }
      ],
      "source": [
        "# Prediciendo con parametros de gd_1\n",
        "y_pred_prob = f(X_test,gd_2.coeficientes)\n",
        "\n",
        "# Convertir probabilidades en clases (0 o 1)\n",
        "y_pred_class = (y_pred_prob >= 0.5).astype(int)\n",
        "\n",
        "print(\"accuracy: {}\".format(show_metric(accuracy_score(y_test, y_pred_class))))\n",
        "print(\"precision: {}\".format(show_metric(precision_score(y_test, y_pred_class))))\n",
        "print(\"recall: {}\".format(show_metric(recall_score(y_test, y_pred_class))))\n",
        "print(\"F1 score: {}\".format(show_metric(f1_score(y_test, y_pred_class))))\n",
        "print(\"matriz de confusion: \", confusion_matrix(y_test, y_pred_class))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q22jcOmcVEOr",
        "outputId": "fd2815bd-a757-4ef4-c575-798d6e330364"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "skLearn - accuracy: 84.62%\n",
            "skLearn - precision: 92.31%\n",
            "skLearn - recall: 76.60%\n",
            "skLearn - F1 score: 83.72%\n"
          ]
        }
      ],
      "source": [
        "model = LogisticRegression(fit_intercept=False, max_iter=1000, solver='lbfgs')  # solver por defecto\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)         # Predicciones (0 o 1)\n",
        "#y_pred_prob = model.predict_proba(X_test)[:, 1]  # Probabilidades\n",
        "\n",
        "print(\"skLearn - accuracy: {}\".format(show_metric(accuracy_score(y_test, y_pred))))\n",
        "print(\"skLearn - precision: {}\".format(show_metric(precision_score(y_test, y_pred))))\n",
        "print(\"skLearn - recall: {}\".format(show_metric(recall_score(y_test, y_pred))))\n",
        "print(\"skLearn - F1 score: {}\".format(show_metric(f1_score(y_test, y_pred))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zInBohO0W60t"
      },
      "source": [
        "Parte B."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gd_logreg_binary(X, y, lr=0.1, n_iter=5000, tol=1e-6):\n",
        "    \"\"\"\n",
        "    Descenso de gradiente para regresión logística binaria.\n",
        "    Retorna:\n",
        "      w: vector de parámetros (d,1)\n",
        "      hist: lista del valor del log-likelihood en cada iteración\n",
        "    \"\"\"\n",
        "    n, d = X.shape\n",
        "    w = np.zeros((d, 1))\n",
        "    hist = []\n",
        "    \n",
        "    for i in range(n_iter):\n",
        "        z = X @ w\n",
        "        h = 1 / (1 + np.exp(-z))\n",
        "        grad = (1/n) * (X.T @ (h - y))\n",
        "        w -= lr * grad\n",
        "        \n",
        "        # log-likelihood (con estabilidad numérica)\n",
        "        ll = np.mean(y * np.log(h + 1e-9) + (1 - y) * np.log(1 - h + 1e-9))\n",
        "        hist.append(ll)\n",
        "        \n",
        "        # criterio de convergencia\n",
        "        if i > 0 and abs(hist[-1] - hist[-2]) < tol:\n",
        "            break\n",
        "            \n",
        "    return w, hist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_RQVrdRW4_I",
        "outputId": "8f4cb9cb-921a-49d5-ffb6-1144ecf631df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== From-Scratch OvA (Wine) ===\n",
            "Accuracy: 0.9814814814814815\n",
            "Confusion matrix:\n",
            " [[18  0  0]\n",
            " [ 1 20  0]\n",
            " [ 0  0 15]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9474    1.0000    0.9730        18\n",
            "           1     1.0000    0.9524    0.9756        21\n",
            "           2     1.0000    1.0000    1.0000        15\n",
            "\n",
            "    accuracy                         0.9815        54\n",
            "   macro avg     0.9825    0.9841    0.9829        54\n",
            "weighted avg     0.9825    0.9815    0.9815        54\n",
            "\n",
            "\n",
            "=== sklearn LogisticRegression (OVR) ===\n",
            "Accuracy: 0.9814814814814815\n",
            "Confusion matrix:\n",
            " [[18  0  0]\n",
            " [ 1 20  0]\n",
            " [ 0  0 15]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9474    1.0000    0.9730        18\n",
            "           1     1.0000    0.9524    0.9756        21\n",
            "           2     1.0000    1.0000    1.0000        15\n",
            "\n",
            "    accuracy                         0.9815        54\n",
            "   macro avg     0.9825    0.9841    0.9829        54\n",
            "weighted avg     0.9825    0.9815    0.9815        54\n",
            "\n",
            "\n",
            "Norma L2 coef (ours) : [6.1073 7.0987 4.8017]\n",
            "Norma L2 coef (sklearn): [3.0003 3.2925 2.5856]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1273: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# PART B — One-vs-All (Wine) con tu lógica\n",
        "# ============================================\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "USE_INTERCEPT = True   # si en tu Parte A YA agregas el intercepto dentro del modelo, cambia a False\n",
        "\n",
        "# helpers mínimos (solo si faltan por nombre)\n",
        "try:\n",
        "    add_intercept\n",
        "except NameError:\n",
        "    def add_intercept(X): return np.hstack([np.ones((X.shape[0],1)), X])\n",
        "\n",
        "try:\n",
        "    sigmoid\n",
        "except NameError:\n",
        "    def sigmoid(z): return 1/(1+np.exp(-z))\n",
        "\n",
        "# === 1) Cargar Wine ===\n",
        "wine = load_wine()\n",
        "X = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
        "y = pd.Series(wine.target)  # {0,1,2}\n",
        "\n",
        "# === 2) Split 70/30 (estratificado) ===\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=RANDOM_STATE, stratify=y\n",
        ")\n",
        "\n",
        "# === 3) Estandarizar TODAS las features (fit en train, transform en test) ===\n",
        "sc = StandardScaler()\n",
        "X_trs = sc.fit_transform(X_tr)\n",
        "X_tes = sc.transform(X_te)\n",
        "\n",
        "# === 4) Intercepto (según tu pipeline) ===\n",
        "if USE_INTERCEPT:\n",
        "    Xtr = add_intercept(X_trs)\n",
        "    Xte = add_intercept(X_tes)\n",
        "else:\n",
        "    Xtr = X_trs\n",
        "    Xte = X_tes\n",
        "\n",
        "ytr = y_tr.values\n",
        "yte = y_te.values\n",
        "K = np.unique(ytr).size\n",
        "d = Xtr.shape[1]\n",
        "\n",
        "# === 5) Entrenar OvA usando tu gd_logreg_binary ===\n",
        "W_ova = np.zeros((d, K))  # cada columna = w_k\n",
        "histories_ova = []\n",
        "\n",
        "for k in range(K):\n",
        "    y_bin = (ytr == k).astype(int).reshape(-1,1)\n",
        "    w_k, hist_k = gd_logreg_binary(Xtr, y_bin, lr=0.1, n_iter=6000, tol=1e-9)\n",
        "    W_ova[:, [k]] = w_k\n",
        "    histories_ova.append(hist_k)\n",
        "\n",
        "# === 6) Predicción: argmax de probabilidades sigmoide ===\n",
        "probs_test = sigmoid(Xte @ W_ova)      # (n_test, K)\n",
        "y_pred_ova = np.argmax(probs_test, axis=1)\n",
        "\n",
        "print(\"=== From-Scratch OvA (Wine) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(yte, y_pred_ova))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(yte, y_pred_ova))\n",
        "print(classification_report(yte, y_pred_ova, digits=4, zero_division=0))\n",
        "\n",
        "# === 7) Comparación con sklearn OVR ===\n",
        "sk_ovr = LogisticRegression(\n",
        "    multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=RANDOM_STATE\n",
        ")\n",
        "sk_ovr.fit(X_trs, y_tr)\n",
        "y_pred_sk = sk_ovr.predict(X_tes)\n",
        "\n",
        "print(\"\\n=== sklearn LogisticRegression (OVR) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_te, y_pred_sk))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_te, y_pred_sk))\n",
        "print(classification_report(y_te, y_pred_sk, digits=4, zero_division=0))\n",
        "\n",
        "# (opc) comparar magnitud de coeficientes (sin intercepto)\n",
        "try:\n",
        "    coef_norm_ours = np.linalg.norm(W_ova[1:, :], axis=0) if USE_INTERCEPT else np.linalg.norm(W_ova, axis=0)\n",
        "    coef_norm_sk   = np.linalg.norm(sk_ovr.coef_, axis=1)\n",
        "    print(\"\\nNorma L2 coef (ours) :\", np.round(coef_norm_ours, 4))\n",
        "    print(\"Norma L2 coef (sklearn):\", np.round(coef_norm_sk, 4))\n",
        "except Exception as e:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqlPsRg4XDWA"
      },
      "source": [
        "PARTE. C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Derive the gradient of the log-likelihood function for muticlass classification (check the notebook for session 4)\n",
        "\n",
        "    \\begin{align*}\n",
        "    L(\\theta) & = \\prod_{i=1}^n P_\\theta (y^{(i)} \\mid x^{(i)}) = \\prod_{i=1}^n \\vec \\sigma(\\vec z^{(i)})_{y^{(i)}} \\\\\n",
        "    & = \\prod_{i=1}^n \\left( \\frac{\\exp(\\theta_{y^{(i)}}^\\top x^{(i)})}{\\sum_{l=1}^K \\exp(\\theta_l^\\top x^{(i)})} \\right). \\\\\n",
        "    \\end{align*}\n",
        "\n",
        "    La funcion **log-likelihood $\\ell(\\theta)$** tiene la forma: \n",
        "\n",
        "    \\begin{align*}\n",
        "    \\ell(\\theta)=\\log[L(\\theta)]=\\sum_{i=1}^n\\left[\\theta_{y^{(i)}}x^{(i)}-\\ln\\left(\\sum_{j=1}^k\\exp(\\theta_jx^{(i)})\\right)\\right]\n",
        "    \\end{align*}\n",
        "\n",
        "    Así que derivando con respecto a la clase **m** con su **vector de parámetros $\\theta_m$** para una observación $\\text{i}$ :\n",
        "\n",
        "    **Forma expandida**:\n",
        "\n",
        "    \\begin{align*}\n",
        "            \\ell(\\theta)=\\sum_{i=1}^n\\left[\\ln\\left(e^{(\\beta_{m0}+\\beta_{m1}x^{(i)}_1...+\\beta_{m p}x^{(i)}_p)}\\right)-\\ln\\left(\\sum_{j=1}^Ke^{(\\beta_{j0}+\\beta_{j1}x^{(i)}_1...+\\beta_{j p}x^{(i)}_p)}\\right)\\right]\n",
        "    \\end{align*}\n",
        "\n",
        "    Antes de derivar, para el $1^{er}$ término por propiedad de logaritmos:\n",
        "\n",
        "    \\begin{align*}\n",
        "        \\ln\\left(e^{(\\beta_{m0}+\\beta_{m1}x^{(i)}_1...+\\beta_{m p}x^{(i)}_p)}\\right) & = (\\beta_{m0}+\\beta_{m1}x^{(i)}_1...+\\beta_{m p}x^{(i)}_p)\n",
        "    \\end{align*}\n",
        "\n",
        "    Entonces quedaría:\n",
        "\n",
        "    \\begin{align*}\n",
        "            \\ell(\\theta)=\\sum_{i=1}^n\\left[(\\beta_{m0}+\\beta_{m1}x^{(i)}_1...+\\beta_{m p}x^{(i)}_p)-\\ln\\left(\\sum_{j=1}^Ke^{(\\beta_{j0}+\\beta_{j1}x^{(i)}_1...+\\beta_{j p}x^{(i)}_p)}\\right)\\right]\n",
        "    \\end{align*}\n",
        "\n",
        "    Empezamos a derivar:\n",
        "\n",
        "    \\begin{align*}\n",
        "    \\frac{\\partial}{\\partial\\theta_m}\\left(\\sum_{i=1}^n\\left[\\underbrace{(\\beta_{m0}+\\beta_{m1}x^{(i)}_1...+\\beta_{m p}x^{(i)}_p)}_{1^{er}\\text{ término}}\\;\\underbrace{-\\ln\\left(\\sum_{j=1}^Ke^{(\\beta_{j0}+\\beta_{j1}x^{(i)}_1...+\\beta_{j p}x^{(i)}_p)}\\right)}_{2^{do}\\text{ término}}\\right]\\right)\n",
        "    \\end{align*}\n",
        "\n",
        "    - Para el $1^\\text{er}$ término:\n",
        "\n",
        "        \\begin{align*}\n",
        "        \\frac{\\partial}{\\partial\\theta_m} (\\beta_{m0}+\\beta_{m1}x^{(i)}_1...+\\beta_{m p}x^{(i)}_p)\n",
        "        \\end{align*}\n",
        "    \n",
        "        $\\theta_m$ es un vector de parámetros conformado por todos sus $\\beta\\text{'s}$. Al derivar con respecto a $\\theta_m$ estamos derivando parcialmente con respecto a todos sus componenetes $\\beta_m$:\n",
        "\n",
        "        Para $\\beta_{m0}$: \n",
        "        \n",
        "        \\begin{aligned}\n",
        "        \\frac{\\partial}{\\partial\\beta_{m0}} (\\beta_{m0}+\\beta_{m1}x^{(i)}_1...+\\beta_{m p}x^{(i)}_p) & = 1\n",
        "        \\end{aligned}\n",
        "\n",
        "        Para $\\beta_{m1}$: \n",
        "        \n",
        "        \\begin{align*}\n",
        "        \\frac{\\partial}{\\partial\\beta_{m1}} (\\beta_{m0}+\\beta_{m1}x^{(i)}_1...+\\beta_{m p}x^{(i)}_p) & = x^{(i)}_1\n",
        "        \\end{align*}\n",
        "\n",
        "        ... hasta $\\beta_{mp}$: \n",
        "        \n",
        "        \\begin{align*}\n",
        "        \\frac{\\partial}{\\partial\\beta_{mp}} (\\beta_{m0}+\\beta_{m1}x^{(i)}_1...+\\beta_{m p}x^{(i)}_p) & = x^{(i)}_p\n",
        "        \\end{align*}\n",
        "\n",
        "        Resultando en un vector, que es el vector $x$ para la observacion $i$\n",
        "\n",
        "        \\begin{align*}\n",
        "        \\begin{bmatrix}\n",
        "        1 \\\\\n",
        "        x^{(i)}_1 \\\\\n",
        "        x^{(i)}_2 \\\\\n",
        "        ... \\\\\n",
        "        x^{(i)}_p\n",
        "        \\end{bmatrix}\n",
        "        & = x^{(i)}\n",
        "        \\end{align*}\n",
        "\n",
        "        Ahora como estamos tomando una observacion $i$ tenemos que usar **una función indicador** que nos señale si esa observación pertenece a la clase **m**:\n",
        "\n",
        "        \\begin{align*}\n",
        "        \\mathbb{1}\\left\\{ y^{(i)}= m \\right\\}\n",
        "        \\end{align*}\n",
        "\n",
        "        Donde $1$ si esa observación $i$ pertenece a **m**, caso contrario $0$. Quedándonos nuestro primer término:\n",
        "\n",
        "        \\begin{align*}\n",
        "        \\mathbb{1}\\left\\{ y^{(i)}= m \\right\\} x^{(i)}\n",
        "        \\end{align*}\n",
        "\n",
        "    - Para el $2^\\text{do}$ término:\n",
        "\n",
        "        \\begin{align*}\n",
        "        \\frac{\\partial}{\\partial\\theta_m} \\left[ -\\ln\\left(\\sum_{j=1}^Ke^{(\\beta_{j0}+\\beta_{j1}x^{(i)}_1...+\\beta_{j p}x^{(i)}_p)}\\right) \\right]\n",
        "        \\end{align*}\n",
        "\n",
        "        Derivamos lo que esta dentro de $\\ln$, aplicamos regla de la cadena:\n",
        "\n",
        "        \\begin{align*}\n",
        "        -\\frac{1}{\\sum_{j=1}^Ke^{(\\beta_{j0}+\\beta_{j1}x^{(i)}_1...+\\beta_{j p}x^{(i)}_p)}} \\cdot \\frac{\\partial }{\\partial\\theta_m}\\left(\\sum_{j=1}^Ke^{(\\beta_{j0}...)} \\right)\n",
        "        \\end{align*}\n",
        "\n",
        "        Al derivar toda la sumatoria con respecto a $\\theta_m$ **solo nos importa el termino de la sumatoria que contenga los $\\beta_m$** ya que los demás que no dependen de $\\theta_m$ se vuelven $0\\text{'s}$, así que reescribimos:\n",
        "\n",
        "        \\begin{align*}\n",
        "        -\\frac{1}{\\sum_{j=1}^Ke^{(\\beta_{j0}+\\beta_{j1}x^{(i)}_1...+\\beta_{j p}x^{(i)}_p)}} \\cdot \\frac{\\partial }{\\partial\\theta_m} \\left(e^{(\\beta_{m0}+\\beta_{m1}x^{(i)}_1...+\\beta_{m p}x^{(i)}_p)} \\right)\n",
        "        \\end{align*}\n",
        "\n",
        "        Derivamos $\\text{euler}$ y volvemos a aplicar regla de la cadena al exponente de $e$:\n",
        "\n",
        "        \\begin{align*}\n",
        "        -\\frac{1}{\\sum_{j=1}^Ke^{(\\beta_{j0}+\\beta_{j1}x^{(i)}_1...+\\beta_{j p}x^{(i)}_p)}} \\cdot e^{(\\beta_{m0}+\\beta_{m1}x^{(i)}_1...+\\beta_{m p}x^{(i)}_p)} \\cdot \n",
        "        \\frac{\\partial }{\\partial\\theta_m}\\left(\\beta_{m0}+\\beta_{m1}x^{(i)}_1...+\\beta_{m p}x^{(i)}_p\\right)\n",
        "        \\end{align*}\n",
        "\n",
        "        Pero esto ya lo conocemos del $1^\\text{er}$ término:\n",
        "\n",
        "        \\begin{align*}\n",
        "        \\frac{\\partial}{\\partial\\theta_m} (\\beta_{m0}+\\beta_{m1}x^{(i)}_1...+\\beta_{m p}x^{(i)}_p) & = \n",
        "        \\begin{bmatrix}\n",
        "        1 \\\\\n",
        "        x^{(i)}_1 \\\\\n",
        "        x^{(i)}_2 \\\\\n",
        "        ... \\\\\n",
        "        x^{(i)}_p\n",
        "        \\end{bmatrix}\n",
        "        & = x^{(i)}\n",
        "        \\end{align*}\n",
        "\n",
        "        Entonces el $2^\\text{do}$ término quedaría:\n",
        "\n",
        "        \\begin{align*}\n",
        "        -\\frac{1}{\\sum_{j=1}^Ke^{(\\beta_{j0}+\\beta_{j1}x^{(i)}_1...+\\beta_{j p}x^{(i)}_p)}} \\cdot e^{(\\beta_{m0}+\\beta_{m1}x^{(i)}_1...+\\beta_{m p}x^{(i)}_p)} \\cdot \n",
        "        x^{(i)}\n",
        "        \\end{align*}\n",
        "\n",
        "        \\begin{align*}\n",
        "        -\\frac{e^{(\\beta_{m0}+\\beta_{m1}x^{(i)}_1...+\\beta_{m p}x^{(i)}_p)}}{\\sum_{j=1}^Ke^{(\\beta_{j0}+\\beta_{j1}x^{(i)}_1...+\\beta_{j p}x^{(i)}_p)}} \\cdot \n",
        "        x^{(i)}\n",
        "        \\end{align*}\n",
        "\n",
        "        Esta fracción es **softmax Regression en forma extendida**:\n",
        "\n",
        "        \\begin{align*}\n",
        "        \\frac{e^{(\\beta_{m0}+\\beta_{m1}x^{(i)}_1+...+\\beta_{mp}x^{(i)}_p)}}{\\sum_{j=1}^K e^{(\\beta_{j0}+\\beta_{j1}x^{(i)}_1+...+\\beta_{jp}x^{(i)}_p)}} = P(y^{(i)}=m | x^{(i)}) = p_{im}\n",
        "        \\end{align*}\n",
        "\n",
        "        Por lo tanto el $2^\\text{do}$ término nos queda:\n",
        "\n",
        "        \\begin{align*}\n",
        "        -p_{im}x^{(i)}\n",
        "        \\end{align*}\n",
        "\n",
        "    #### Uniendo términos:\n",
        "\n",
        "    - $1^\\text{er}$ término:\n",
        "\n",
        "    \\begin{align*}\n",
        "    \\mathbb{1}\\left\\{ y^{(i)}= m \\right\\} x^{(i)}\n",
        "    \\end{align*}\n",
        "\n",
        "    - $2^\\text{do}$ término:\n",
        "\n",
        "    \\begin{align*}\n",
        "    -p_{im}x^{(i)}\n",
        "    \\end{align*}\n",
        "\n",
        "    - Función original:\n",
        "\n",
        "    \\begin{align*}\n",
        "    \\frac{\\partial\\ell(\\theta)}{\\partial\\theta_m}=\\sum_{i=1}^n\\left[\\underbrace{(\\beta_{m0}+\\beta_{m1}x^{(i)}_1...+\\beta_{m p}x^{(i)}_p)}_{1^{er}\\text{ término}}\\;\\underbrace{-\\ln\\left(\\sum_{j=1}^Ke^{(\\beta_{j0}+\\beta_{j1}x^{(i)}_1...+\\beta_{j p}x^{(i)}_p)}\\right)}_{2^{do}\\text{ término}}\\right]\n",
        "    \\end{align*}\n",
        "\n",
        "\n",
        "    \\begin{align*}\n",
        "    \\frac{\\partial\\ell(\\theta)}{\\partial\\theta_m}=\\sum_{i=1}^n\\left(\\mathbb{1}\\left\\{ y^{(i)}= m \\right\\} x^{(i)} -p_{im}x^{(i)}\\right)\n",
        "    \\end{align*}\n",
        "\n",
        "    Factor común y finalmente **gradiente final**: \n",
        "\n",
        "    \\begin{align*}\n",
        "    \\boxed{\n",
        "    \\frac{\\partial\\ell(\\theta)}{\\partial\\theta_m}=\\sum_{i=1}^n\\left(\\mathbb{1}\\left\\{ y^{(i)}= m \\right\\}-p_{im}\\right) x^{(i)} \n",
        "    }\n",
        "    \\end{align*}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hWdjJuORW_zJ",
        "outputId": "ffe82395-820d-41da-aa44-c4793c62c2e5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== From-Scratch Softmax (Wine) ===\n",
            "Accuracy: 0.9814814814814815\n",
            "Confusion matrix:\n",
            " [[18  0  0]\n",
            " [ 1 20  0]\n",
            " [ 0  0 15]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9474    1.0000    0.9730        18\n",
            "           1     1.0000    0.9524    0.9756        21\n",
            "           2     1.0000    1.0000    1.0000        15\n",
            "\n",
            "    accuracy                         0.9815        54\n",
            "   macro avg     0.9825    0.9841    0.9829        54\n",
            "weighted avg     0.9825    0.9815    0.9815        54\n",
            "\n",
            "\n",
            "=== sklearn LogisticRegression (Multinomial, lbfgs) ===\n",
            "Accuracy: 0.9814814814814815\n",
            "Confusion matrix:\n",
            " [[18  0  0]\n",
            " [ 1 20  0]\n",
            " [ 0  0 15]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9474    1.0000    0.9730        18\n",
            "           1     1.0000    0.9524    0.9756        21\n",
            "           2     1.0000    1.0000    1.0000        15\n",
            "\n",
            "    accuracy                         0.9815        54\n",
            "   macro avg     0.9825    0.9841    0.9829        54\n",
            "weighted avg     0.9825    0.9815    0.9815        54\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# PART C — Multinomial (Softmax) from scratch\n",
        "# (mismo split/escala que Part B)\n",
        "# ============================================\n",
        "def softmax(Z):\n",
        "    Zs = Z - np.max(Z, axis=1, keepdims=True)\n",
        "    EZ = np.exp(Zs)\n",
        "    return EZ / np.sum(EZ, axis=1, keepdims=True)\n",
        "\n",
        "def one_hot_int(y, K):\n",
        "    Y = np.zeros((y.shape[0], K))\n",
        "    Y[np.arange(y.shape[0]), y] = 1.0\n",
        "    return Y\n",
        "\n",
        "def nll_multinomial_and_grad(W, X, y_int):\n",
        "    # W: (d,K), X: (n,d)\n",
        "    P = softmax(X @ W)                 # (n,K)\n",
        "    Y = one_hot_int(y_int, W.shape[1]) # (n,K)\n",
        "    eps = 1e-12\n",
        "    nll = -np.mean(np.sum(Y * np.log(P + eps), axis=1))\n",
        "    grad = (X.T @ (P - Y)) / X.shape[0]\n",
        "    return nll, grad\n",
        "\n",
        "def gd_logreg_multinomial(X, y_int, lr=0.1, n_iter=6000, tol=1e-9, verbose=False):\n",
        "    d = X.shape[1]\n",
        "    K = np.unique(y_int).size\n",
        "    W = np.zeros((d, K))\n",
        "    hist = []\n",
        "    prev = None\n",
        "    for i in range(n_iter):\n",
        "        loss, g = nll_multinomial_and_grad(W, X, y_int)\n",
        "        W -= lr * g\n",
        "        hist.append(loss)\n",
        "        if verbose and i % 200 == 0:\n",
        "            print(f\"iter {i:4d}  NLL={loss:.6f}\")\n",
        "        if prev is not None and abs(prev - loss) < tol:\n",
        "            break\n",
        "        prev = loss\n",
        "    return W, hist\n",
        "\n",
        "# Reutilizamos X_trs/X_tes del Part B; añadimos intercepto según tu pipeline\n",
        "if USE_INTERCEPT:\n",
        "    Xtr_m = add_intercept(X_trs)\n",
        "    Xte_m = add_intercept(X_tes)\n",
        "else:\n",
        "    Xtr_m = X_trs\n",
        "    Xte_m = X_tes\n",
        "\n",
        "ytr_m = y_tr.values\n",
        "yte_m = y_te.values\n",
        "K = np.unique(ytr_m).size\n",
        "\n",
        "# Entrena (dos lrs para ver convergencia si quieres)\n",
        "W_soft, hist_soft = gd_logreg_multinomial(Xtr_m, ytr_m, lr=0.1, n_iter=6000, tol=1e-9)\n",
        "# W_soft2, hist_soft2 = gd_logreg_multinomial(Xtr_m, ytr_m, lr=0.05, n_iter=6000, tol=1e-9)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(hist_soft, label=\"lr=0.1\")\n",
        "# plt.plot(hist_soft2, label=\"lr=0.05\")\n",
        "plt.xlabel(\"Iteración\"); plt.ylabel(\"NLL (train)\")\n",
        "plt.title(\"Convergencia NLL — Softmax (Wine)\")\n",
        "plt.legend(); plt.show()\n",
        "\n",
        "# Predicción\n",
        "P_te = softmax(Xte_m @ W_soft)\n",
        "y_pred_soft = np.argmax(P_te, axis=1)\n",
        "\n",
        "print(\"=== From-Scratch Softmax (Wine) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(yte_m, y_pred_soft))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(yte_m, y_pred_soft))\n",
        "print(classification_report(yte_m, y_pred_soft, digits=4, zero_division=0))\n",
        "\n",
        "# Comparación sklearn multinomial\n",
        "sk_multi = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", max_iter=5000, random_state=RANDOM_STATE)\n",
        "sk_multi.fit(X_trs, y_tr)\n",
        "y_pred_sk_multi = sk_multi.predict(X_tes)\n",
        "\n",
        "print(\"\\n=== sklearn LogisticRegression (Multinomial, lbfgs) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_te, y_pred_sk_multi))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_te, y_pred_sk_multi))\n",
        "print(classification_report(y_te, y_pred_sk_multi, digits=4, zero_division=0))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
